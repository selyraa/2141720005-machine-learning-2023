{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOj8S+DfkzU/xMOjk2eELgp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selyraa/2141720005-machine-learning-2023/blob/main/JS10-Recurrent%20Neural%20Network%20(RNN)/praktikum_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Praktikum 2\n",
        "Generator Teks dengan RNN"
      ],
      "metadata": {
        "id": "_CEfjcI__inl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "Import TensorFlow"
      ],
      "metadata": {
        "id": "4DIL9BYOFbJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MX6Da_af_dXH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset Shakespeare"
      ],
      "metadata": {
        "id": "scpyKsXKF3Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kbO2r92Fghl",
        "outputId": "79ce2657-9d3d-454e-d767-b20df4a81600"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "umyN24HxGInM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHQV9tARF5R7",
        "outputId": "a523957b-83f7-4ba8-bd02-46868c981fa2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwOqirVrGOLZ",
        "outputId": "012f43dc-304c-4b2f-e407-367cd1c51dda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRvzXYJ4GVsq",
        "outputId": "22d6ef2b-d110-4a47-8e61-b854db2ebbde"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print unique characters\n",
        "for char in vocab:\n",
        "    print(char, end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1q7QMnHIKMa",
        "outputId": "bfcc728d-5343-4dd6-d9cf-6ead642d5997"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   ! $ & ' , - . 3 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Olah Teks"
      ],
      "metadata": {
        "id": "1e8AseEWH0Xl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorize Teks"
      ],
      "metadata": {
        "id": "uU8l4znrJCmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ],
      "metadata": {
        "id": "OIu9pjuMJFuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iheB-8ZGIQkm",
        "outputId": "48d495be-15ec-42c0-cc7b-c5dfd620837f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sekarang buat tf.keras.layers.StringLookup layer:"
      ],
      "metadata": {
        "id": "5TcFZnC0LJsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
      ],
      "metadata": {
        "id": "s6OG1PcSJYQY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "perintah diatas mengconvert token menjadi id"
      ],
      "metadata": {
        "id": "Jx62JPLJLYfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "963Z3L-dLU-o",
        "outputId": "f797c646-7759-4d52-d51f-f3612044139a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode"
      ],
      "metadata": {
        "id": "chxnvVTlYUwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "B0sObC6uLc5O"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter tf.RaggedTensor:"
      ],
      "metadata": {
        "id": "qabuA_SPYcLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RIpTdvoXw_m",
        "outputId": "d3feca64-08be-4639-a54b-dfb35d35c894"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoXzdaZZYX-1",
        "outputId": "b81a96dc-004e-489f-cd5b-ac001ee31024"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "OtF7JhJmYn7c"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediksi"
      ],
      "metadata": {
        "id": "RLFJUPcsZEmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membuat Training Set dan Target"
      ],
      "metadata": {
        "id": "YSB6IBYCZHjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bHEqISCZBlt",
        "outputId": "80e7c866-4d97-4052-aefa-13d5cf45a494"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "QIMXGoXsZQNn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0i6FtI1ZUJ2",
        "outputId": "4ebce453-f9a4-438e-f090-75d8b1f3c28a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100"
      ],
      "metadata": {
        "id": "kGbc6MVGZrEK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ],
      "metadata": {
        "id": "f0LOUSzJabl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIVqQTEYaELm",
        "outputId": "3f866c2b-78d5-42fd-e39a-ac7bda10a2d7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ],
      "metadata": {
        "id": "VY78qrFaa3Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wslsP-OAaful",
        "outputId": "22d60afa-5ed5-48ef-fd50-d645495326ae"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk pelatihan, Anda memerlukan kumpulan data pasangan (input, label). Dimana input dan label merupakan urutan. Pada setiap langkah waktu, inputnya adalah karakter saat ini dan labelnya adalah karakter berikutnya. Berikut adalah fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu:"
      ],
      "metadata": {
        "id": "7MfYqUMBbL2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ],
      "metadata": {
        "id": "opzxqqSXa-Cq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6H-t9Mebk_B",
        "outputId": "9ba02951-de81-4514-80b2-98cad739952f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "fmsj-cYybnkr"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBAvhx1sb2KJ",
        "outputId": "b80f922a-9890-4367-aa9e-6fa60a5b3f64"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membuat Batch Training\n",
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ],
      "metadata": {
        "id": "yjBuEPntcTTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smwEj831cAMz",
        "outputId": "0f10206c-927c-4f19-fa72-7c9973f149bc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membuat Model"
      ],
      "metadata": {
        "id": "1UFdjpdvcro0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "nWb5toxMccsn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "CIRhoWLpc4_z"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "Fui7NL-Lc6-L"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uji Model"
      ],
      "metadata": {
        "id": "qPVl5yQ6dASL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMnWrLjBc9WA",
        "outputId": "085ebeed-4404-42e1-d901-276e9eaeb5ab"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpK0HsXydfxx",
        "outputId": "4979005e-f148-49ba-8423-0f2ad63841bd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "c9572vG0dSaO"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wmcvoqZdVY3",
        "outputId": "56f4d868-0dd9-46c8-a5c3-d192a7cf21bc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8, 64, 16, 33, 45, 11, 26, 35, 51, 51, 26, 54, 25, 35, 16, 56, 56,\n",
              "       52, 34, 39, 31, 52, 14, 54,  6, 60, 31, 14, 48, 34,  4, 11, 57, 19,\n",
              "       60, 60, 15, 39, 58, 32, 43, 53, 29, 44,  3,  9, 57, 41, 32, 24,  7,\n",
              "       51, 50, 54, 36, 22, 11, 24, 40, 39, 43, 38, 18,  9,  1,  9, 53, 47,\n",
              "       28, 60, 65, 10, 12, 43,  9, 34, 44, 56, 52, 16, 28, 30, 61, 49, 38,\n",
              "       51, 35, 61,  2, 58,  8, 58,  0, 33, 14, 11, 17, 51, 45, 37])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dekode kode berikut untuk melihat teks yang diprediksi oleh model tidak terlatih ini:"
      ],
      "metadata": {
        "id": "iQVn09PjeQmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUD6JykleCQ2",
        "outputId": "d9418d1d-220d-4a5f-d497-dbf800c7b482"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'rby, Buckingham;\\nAnd say it is the queen and her allies\\nThat stir the king against the duke my broth'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"-yCTf:MVllMoLVCqqmUZRmAo'uRAiU$:rFuuBZsSdnPe!.rbSK,lkoWI:KaZdYE.\\n.nhOuz3;d.UeqmCOQvjYlVv s-s[UNK]TA:DlfX\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model\n",
        "### Tambahan optimizer dan fungsi loss\n",
        "loss function tf.keras.losses.sparse_categorical_crossentropy standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag from_logits."
      ],
      "metadata": {
        "id": "3P8r6gD0eeAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "DDEEYiQIeS5M"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IaGO175hRWD",
        "outputId": "a97cad59-3f11-4fe9-8ca0-2867f08d86af"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1898847, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model yang baru diinisialisasi tidak boleh terlalu yakin dengan dirinya sendiri, semua log keluaran harus memiliki besaran yang sama. Untuk mengonfirmasi hal ini, Anda dapat memeriksa bahwa eksponensial dari loss rata-rata harus kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ],
      "metadata": {
        "id": "dky5dzO1hmLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWtoUmMyhX-y",
        "outputId": "8ed8ca34-01c0-413f-9849-91d5f68d8cb7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.015175"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ],
      "metadata": {
        "id": "SotmR9pJhpuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "9WPI70RuhiNE"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Konfigurasi Checkpoints\n",
        "Gunakan tf.keras.callbacks.ModelCheckpoint untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ],
      "metadata": {
        "id": "N7E89t4Zhvju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "23AY9Ob2hsi-"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lakukan Proses Training"
      ],
      "metadata": {
        "id": "o4Xb0R-Ch4mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "aXC_QdPEh2R-"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E3BsQpxh9F2",
        "outputId": "125e2407-452f-48ed-ac22-e797bf1ca221"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 15s 52ms/step - loss: 2.7190\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.9912\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.7121\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 12s 54ms/step - loss: 1.5507\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 1.4510\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 14s 52ms/step - loss: 1.3834\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.3316\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.2870\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 14s 56ms/step - loss: 1.2471\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 1.2068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Teks\n",
        "\n",
        "Berikut ini membuat prediksi satu langkah:"
      ],
      "metadata": {
        "id": "CV0hF8Q4iGJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "xSpe_M7CiBQE"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "fseLrMJeic8r"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLaFPvcFifh_",
        "outputId": "63f00744-4397-4de5-92b3-81003899891a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Write us her heaven be? let him be a man!\n",
            "O my countryman, or an ountelleg on the gate\n",
            "O'er tittest death me my native brother-his\n",
            "Admirates and as heir ask,\n",
            "Not for the wind.\n",
            "\n",
            "ISABELLA:\n",
            "My lord, you this danger: live--thine empty shades\n",
            "Mad send 'twas the king is Clarence in the easy, all.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Gardenes, sir, an hour, Calliel,'s disaffears renown.\n",
            "Courtay to him; if you colour'd\n",
            "The secret spoot which libs dried-fellow.\n",
            "\n",
            "RAMPLONA:\n",
            "Master, that who mayst to dim,\n",
            "A back cook broke above The back, God and Boll\n",
            "Meterminers, he,\n",
            "My boots light stay for me; I cannot gurst: gentle,\n",
            "To fight by this at once! and will we be kill'd?\n",
            "If childish he is one laughs: my sauges, I both should brand Greed:\n",
            "Come, gear me see, to sinken from change\n",
            "Speak blueges: thine one hig news? It is\n",
            "not infection was a time may gracious point,\n",
            "In some wounds of Henetial stopp'd the sea\n",
            "As many you a fteen, thine image.\n",
            "I'll now we hear me-spritest in the spair with thee!\n",
            "\n",
            "QUEEN:\n",
            "My liege, my uncle, i \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.6342718601226807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNTARNQ0ilR6",
        "outputId": "8ddccd5e-9834-4129-cb77-af3950eab6dc"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nOr I'll send him to action; and me\\ntoo fault on my hand.\\nOf a goldly trick in mine huntagens,\\nTo this, I shall, sil in becomed morrow.\\nCome, I think, in heaven still.\\n\\nALO:\\nGod save thus better prisoner?\\n\\nGONZALO:\\nI play the rest have said to do him.\\n\\nKING EDWARD IV:\\nWhat duist the name, my liege, and leaduned him\\nonce change to son, and by my friends.\\n\\nCOMINIUS:\\nNow, but now is indeed come?\\n\\nPOLIXENES:\\nA bight o' the continut storm!\\nIs respite itself foldies makes. I will meet\\nBut one that bring him fres a house, or say\\nFor ever staren for your chide.\\n\\nMAPETES:\\nI wish you, inprisonment\\nIs thou know'st to the sound Bosemparable him.\\n\\nBUSHIF:\\nWhy, is not poor lett!'s your sovereity\\nI have been but a boy gevered off;\\nFor boardey past be death, but straight has but three\\nThan time she ishes; and this at humble slave,\\nBut to the black prophecy babe draw fights\\nAs madam suck man'st my heaven, boy it in\\nFrance, and be gently. Come, my lord.\\n\\nGLOUCESTER:\\nIn Gloucester, man on fair princes!\\n\\n\"\n",
            " b\"ROMEO:\\nIt is a mine orcomand.\\n\\nARCISTAND:\\nOme to que three-lorden your thich since!\\n\\nCLIOMERO:\\nGive a litter, this axeards,\\nTo be his furstier, citizens!'\\nTherefore stir more behind to puck the county born\\ngo thank hither hence\\nwhich for conquitation of his pain:\\n'Tis throws a taste Buing to be God's man,\\nThrough sometimes given e'er by her affairs;\\nAnd in the sea much confornsmed joy\\nAnd his very speriman: believe him! God, so quaist\\nEssilve, I before imputaty; and\\ngreat heir more villain, I never drawn at home,\\nAs God's ware now, and know not white,\\nHe chied against the Ruplanus, that worthiels\\nhad been light as other had.\\n\\nANTONIO:\\nWe came to three and the mattor.\\n\\nTRANIO:\\nSir, I had rather to Vincentio.\\n\\nNORTHUMBERLAND:\\nMy robby live!\\n\\nBUCKINGHAM:\\nGood quickly drawn majys; you\\nmake her lies: I swear I not last.\\n\\nCLIFFORD:\\nI knew thee hath grieven, coubsed me,\\nGood king o' dram for this any thing. Sir many joy,\\nIt is a bungeticled with her purpose\\nMore than you must to our earth!\\nIt is a \"\n",
            " b\"ROMEO:\\nHeard your host six it were a kingdom! speak you, sir,\\nwhence Marcius's suffer? than I must not live.\\n\\nDUKE OF AUMERLE:\\nEdward I see\\nCould I'll give the king.\\n\\nCLIFFORD:\\nHow now! why have the law, Baptista May beggar?\\n\\nBAPTISTA:\\nWomer, shall we perce me a ghostly order?\\nLet moons of late nor warm yourself:\\nI never made their skiffs grieves a his.\\n\\nANTONIO:\\nMeath, but that 'twixty self, am I\\nkneel on, as you know with him.\\n\\nCLARENCE:\\nO, poison! hear you? Say, then give me to scape hag born\\nMy wombbed; I hope for both his\\nsafely--tordon thee, to run as it as a man\\nThan fossible very brotherh and deceive\\nAnd when she's my Rome hath borneth these battle\\nMake good state of woence to the weapons\\nFor in this very shiph as any encentaints.\\n\\nEDWARD:\\nHath gone with this dismalous!' 'Tis you, sir;\\nThe gase by fiends of Rome, oath\\nTo Burtueful tribune in the actrone.\\n\\nHORTENSIO:\\nMadam, why, shall welcome your motter?\\n\\nVIRCINIE:\\nRepeal'd in helles, and thriely mine\\nI can do mad; and mistress 'twas\"\n",
            " b\"ROMEO:\\nThou canst not fight,\\nSay'st thou: woman! lett you both primsters. The master dot\\nWhich may goth him coming hat a treacherof.\\n\\nPedant:\\nIt is my lord.\\nTherefore, nobules, sir! my soul\\nstands by too man a foul answer to thy sal,\\nFor what being as kindous best to miser,\\nFor Edward of shame, do not unmany for a\\ndogs in either, come on nought shall be my boy.\\nDod carry that is the wasting strightness?\\n\\nMONTAGUE:\\nMy gracious save day some to, a gentlewoman:\\nI would encounter with his head.\\n\\nROMEO:\\nYou must win my good Burreless:\\nHawly prove the lark! hear'st thou lace is heaven,\\nIs very leaden bears that have changed me stain,\\nHe will to death, and punish'd for his right.\\n\\nBENVOLIO:\\nI'll be you out.\\n\\nFirst Officer:\\nIt were sorrows so, you might have no none.\\nWho have been more behalf our mouths,--\\n\\nADREL:\\nThy story shall be ere the marry scot;\\nCome, come, cope our dage, dived arm\\nThe open'ers my elesciest cursed vigar\\nThan mercy too life and a companing worth;\\nWhich will be past now an arws\"\n",
            " b\"ROMEO:\\nBut shall I be, I have something hold:\\nAnd therein not frownwation; that the infiderst badges brought\\nThe barren other grief, methour and feet up\\nFirst. Look partion; and we have point\\nTo set a hundred I open die.\\n\\nGREEN:\\nEmbany's a feast wethinks any gree o'ers't,\\nThat which I wish'd Richard, decour you.\\n\\nHENRY BOLINGBROKE:\\nOx not so, and thou, like five--\\n\\nANTONIO:\\nAs precention, but inmit it the queen;\\nWhat with his left should custom, Fronts by joy!\\nWho besides you this again,--and embraces\\nthis beasts, or in other cause\\nOne peries out Rome we enter some high sleep.\\n\\nMasters:\\nNo! I have him well crep obswings of husband.\\n\\nGLOUCESTER:\\nAre that or the sounds to pall.\\nHere a Nobth Harging woman; and\\nBianca no iglery brings and woman\\nMore to seem for merry as yours. No; by gone sof\\nMercy him to peason my corqunee,\\nneighbour crossy her toph on me. I say,\\n'Gfordfore forth; look for mercy; hast for much in him\\nThis beaution of which the hateful where have\\nI'll bear the ancient day; and i\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.846832752227783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ekspor Model Generator"
      ],
      "metadata": {
        "id": "iWXXp-fijJ2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSejBantir5r",
        "outputId": "aabc748d-af5a-4a79-c88e-b5d88943b23f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7d2fbc0bba30>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sta3e49jjIzD",
        "outputId": "3023a703-205d-4e80-cafd-e9df2b8fae96"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Ay, if thou seest, would soe Nor ha,\n",
            "And sit for your grace will be free hereins\n",
            "That leads the wea\n"
          ]
        }
      ]
    }
  ]
}