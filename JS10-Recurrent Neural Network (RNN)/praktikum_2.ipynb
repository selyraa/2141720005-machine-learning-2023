{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNCcpkLJXg0s1NUGc1lEiS4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selyraa/2141720005-machine-learning-2023/blob/main/JS10-Recurrent%20Neural%20Network%20(RNN)/praktikum_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Praktikum 2\n",
        "Generator Teks dengan RNN"
      ],
      "metadata": {
        "id": "_CEfjcI__inl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "Import TensorFlow"
      ],
      "metadata": {
        "id": "4DIL9BYOFbJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MX6Da_af_dXH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset Shakespeare"
      ],
      "metadata": {
        "id": "scpyKsXKF3Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kbO2r92Fghl",
        "outputId": "e69ade56-8202-41f8-a2ee-0767c53a618e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "umyN24HxGInM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHQV9tARF5R7",
        "outputId": "5116d0a8-80a6-4b2a-b925-c6ddef82ba0f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwOqirVrGOLZ",
        "outputId": "617131ad-6193-4011-cebf-2449c08f7a27"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRvzXYJ4GVsq",
        "outputId": "d8131a63-8be8-488b-f5f9-4cc3c9416cf3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print unique characters\n",
        "for char in vocab:\n",
        "    print(char, end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1q7QMnHIKMa",
        "outputId": "e17f326c-eb31-4a7e-8f45-0afbc2a65014"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   ! $ & ' , - . 3 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Olah Teks"
      ],
      "metadata": {
        "id": "1e8AseEWH0Xl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorize Teks"
      ],
      "metadata": {
        "id": "uU8l4znrJCmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ],
      "metadata": {
        "id": "OIu9pjuMJFuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iheB-8ZGIQkm",
        "outputId": "1c576857-8b8a-4703-a88d-ca7238c2d5a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sekarang buat tf.keras.layers.StringLookup layer:"
      ],
      "metadata": {
        "id": "5TcFZnC0LJsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
      ],
      "metadata": {
        "id": "s6OG1PcSJYQY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "perintah diatas mengconvert token menjadi id"
      ],
      "metadata": {
        "id": "Jx62JPLJLYfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "963Z3L-dLU-o",
        "outputId": "270ff61c-c5ce-4ff1-fa21-54f9029a7d44"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode"
      ],
      "metadata": {
        "id": "chxnvVTlYUwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "B0sObC6uLc5O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter tf.RaggedTensor:"
      ],
      "metadata": {
        "id": "qabuA_SPYcLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RIpTdvoXw_m",
        "outputId": "211819c1-f21b-422a-fadf-f7aefff0e0df"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoXzdaZZYX-1",
        "outputId": "f536d82d-52e6-4e41-8189-ad986412be30"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "OtF7JhJmYn7c"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediksi"
      ],
      "metadata": {
        "id": "RLFJUPcsZEmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membuat Training Set dan Target"
      ],
      "metadata": {
        "id": "YSB6IBYCZHjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bHEqISCZBlt",
        "outputId": "b2233540-3063-42fd-ad44-98b6cb7f65a8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "QIMXGoXsZQNn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0i6FtI1ZUJ2",
        "outputId": "92162b38-4c67-420e-b3fe-667495b26992"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100"
      ],
      "metadata": {
        "id": "kGbc6MVGZrEK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ],
      "metadata": {
        "id": "f0LOUSzJabl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIVqQTEYaELm",
        "outputId": "d5e705cc-b9f9-4fde-b508-481d28da2096"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ],
      "metadata": {
        "id": "VY78qrFaa3Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wslsP-OAaful",
        "outputId": "1fc4daad-f09c-4f03-e222-3d5bc146041d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk pelatihan, Anda memerlukan kumpulan data pasangan (input, label). Dimana input dan label merupakan urutan. Pada setiap langkah waktu, inputnya adalah karakter saat ini dan labelnya adalah karakter berikutnya. Berikut adalah fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu:"
      ],
      "metadata": {
        "id": "7MfYqUMBbL2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ],
      "metadata": {
        "id": "opzxqqSXa-Cq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6H-t9Mebk_B",
        "outputId": "59bf28b4-2a40-46da-dd62-bbea062ec4e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "fmsj-cYybnkr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBAvhx1sb2KJ",
        "outputId": "0c0a7646-f8ed-4abf-f5ac-82e62e0c05cf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membuat Batch Training\n",
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ],
      "metadata": {
        "id": "yjBuEPntcTTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smwEj831cAMz",
        "outputId": "1221ebdf-e5db-4649-b94e-39183faecb5b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membuat Model"
      ],
      "metadata": {
        "id": "1UFdjpdvcro0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "nWb5toxMccsn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "CIRhoWLpc4_z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "Fui7NL-Lc6-L"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uji Model"
      ],
      "metadata": {
        "id": "qPVl5yQ6dASL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMnWrLjBc9WA",
        "outputId": "48455c7e-1359-4de1-9294-8a028db74073"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpK0HsXydfxx",
        "outputId": "7bd57490-1a08-4719-9f4a-8ce442d00d56"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "c9572vG0dSaO"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wmcvoqZdVY3",
        "outputId": "0d484a00-76bd-48b6-dd5a-00f80c5d77b7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23, 46, 11, 10, 62,  9, 54, 39, 58, 30, 60,  9, 24, 56, 24, 59, 36,\n",
              "       11, 51, 61,  2, 55, 52, 48, 33,  6, 14, 47,  6, 54, 20, 20, 53, 54,\n",
              "       22,  7, 33, 55, 42, 19, 24, 34, 23, 34, 20, 52, 47, 14, 35, 53, 31,\n",
              "       65, 48, 32, 16,  1, 42, 51,  9, 21, 51, 48, 50, 49, 24, 16, 57, 37,\n",
              "       53, 36, 37, 26, 62, 45, 59, 32, 29, 41, 33, 37,  8,  4, 57, 38, 38,\n",
              "       42, 53, 59, 52, 45,  3, 12,  0, 64, 11, 62, 51,  5, 40,  9])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dekode kode berikut untuk melihat teks yang diprediksi oleh model tidak terlatih ini:"
      ],
      "metadata": {
        "id": "iQVn09PjeQmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUD6JykleCQ2",
        "outputId": "77b5ad93-5da6-4165-f8ba-dec4cf1e9ba0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'FROTH:\\nI thank your worship. For mine own part, I never\\ncome into any room in a tap-house, but I am '\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"Jg:3w.oZsQu.KqKtW:lv pmiT'Ah'oGGnoI,TpcFKUJUGmhAVnRziSC\\ncl.HlikjKCrXnWXMwftSPbTX-$rYYcntmf!;[UNK]y:wl&a.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model\n",
        "### Tambahan optimizer dan fungsi loss\n",
        "loss function tf.keras.losses.sparse_categorical_crossentropy standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag from_logits."
      ],
      "metadata": {
        "id": "3P8r6gD0eeAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "DDEEYiQIeS5M"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IaGO175hRWD",
        "outputId": "d8f84f4f-4ee0-4cc7-f698-68167d9ad80d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.19003, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model yang baru diinisialisasi tidak boleh terlalu yakin dengan dirinya sendiri, semua log keluaran harus memiliki besaran yang sama. Untuk mengonfirmasi hal ini, Anda dapat memeriksa bahwa eksponensial dari loss rata-rata harus kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ],
      "metadata": {
        "id": "dky5dzO1hmLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWtoUmMyhX-y",
        "outputId": "4b336c66-afa1-4b3e-8ed9-94cc6ae46b6c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.02478"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ],
      "metadata": {
        "id": "SotmR9pJhpuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "9WPI70RuhiNE"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Konfigurasi Checkpoints\n",
        "Gunakan tf.keras.callbacks.ModelCheckpoint untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ],
      "metadata": {
        "id": "N7E89t4Zhvju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "23AY9Ob2hsi-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lakukan Proses Training"
      ],
      "metadata": {
        "id": "o4Xb0R-Ch4mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "aXC_QdPEh2R-"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E3BsQpxh9F2",
        "outputId": "c51a9a49-453e-4c81-f985-19783ea22a81"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 14s 56ms/step - loss: 2.7329\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.9924\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.7190\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 1.5566\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.4569\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.3886\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.3367\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 1.2918\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.2520\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.2138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Teks\n",
        "\n",
        "Berikut ini membuat prediksi satu langkah:"
      ],
      "metadata": {
        "id": "CV0hF8Q4iGJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "xSpe_M7CiBQE"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "fseLrMJeic8r"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLaFPvcFifh_",
        "outputId": "ac973e80-b854-4fbf-f260-34c0357a6592"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "For me, master, my from meanure,\n",
            "Who comes to any shed Heliting my\n",
            "sadish, and notest her staffomins sharp\n",
            "so hanging; and that's a man-had scannot--to repetted him!\n",
            "Nay, tull us a grave:\n",
            "See them death trow--holk thrie thereof!\n",
            "\n",
            "PRINCE EDWARD:\n",
            "Richmond cause, many.\n",
            "\n",
            "PETRUCHIO:\n",
            "No, if I please your cousin, I will not king you queen?\n",
            "\n",
            "GREMIO:\n",
            "Why, I fell sleep.\n",
            "\n",
            "TRANIO:\n",
            "Can clasence tost this monthned brife.\n",
            "What a madly years to part? sirrah cloaces\n",
            "Twan I regard resign. What wench thou hast die?\n",
            "\n",
            "ANGELO:\n",
            "Let us, you are liege: the show't honour in the wrong\n",
            "That seem'd of that: do been in just, and expect\n",
            "Shall din your youth.\n",
            "\n",
            "CAPULET:\n",
            "Marry, what a way?\n",
            "\n",
            "FRIAR LAURENCE:\n",
            "Relent well go, do not been:\n",
            "I tell thee sir, I do heir; the regal thing\n",
            "Haking thee sweet, that sweetest match'd you.\n",
            "\n",
            "Girl:\n",
            "Then news as easy Presump.\n",
            "\n",
            "MENENIUS:\n",
            "Well, letters you withal, no sound thy life,\n",
            "As man if not for his life become a thrue,\n",
            "And let them both vicours hereaden\n",
            "And me rain and my prevish pra \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.340182065963745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNTARNQ0ilR6",
        "outputId": "c0b095ba-6573-4600-ebf5-06b8f9aa00cc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nNow I aumorr'd; O'r love.\\n\\nSICINIUS:\\nYes, the duke? I'll swear thee.\\n\\nHORTENSIO:\\nIt will breathe ourselves: Sirius in fair,\\nOr let a thank thy father Wastings.\\n\\nKING HENRY VI:\\nTo such pherish-course, titles, men i' them;\\nAnd you draw to fight and prettily and grows\\nthou carsest to tauth a party hear.\\n\\nHENRY BOLINGBROKE:\\nUnto some rotten power in Coriona,\\nWhen he would cannot tell her rich away: this,\\nAnd he did I deep an industinate,\\nHas I'll bend him drame to send so out-too.\\n\\nPERDITA:\\nWould it, till they have had cannot die.\\n\\nESCALUS:\\nI know the man do that,\\nI'll flied dined: may not been bless'd with thy hand;\\nAh, Clarence, ray my name: but that,\\nBe sleep; faith, by noble gold, hangs in teach.\\n\\nBISNOPHO:\\nWell, let it be seen in;\\nBut that I am not. I'll be here, and leaden this,\\nWhose sworn abiest, in ary as they easy.\\n\\nLord ANCESTIO:\\nDo your life, whom downy, he is alone.\\n\\nClown:\\nWell, sir, he, hope seem here, if I traitor't?\\n\\nROMEO:\\nO, belowe!\\nOne king that Bargaret!\\n\\nLEONTES:\\nMan\"\n",
            " b\"ROMEO:\\nIn what is commanded to you.\\n\\nISABELLA:\\nO, madam!\\n\\nISABELLA:\\nWe must can Pray a bard that, God say 'Ay: 'twese.\\n\\nROMEO:\\nI am consent to thee,\\nBut yet you undeed, by unsolent mind.\\n\\nHORTENSIO:\\nNay, I do not sawn; 'Hom of a man at good\\nComion Lord Paris law, if thou dost confess,\\nHencefortal passely in the sleep.\\n\\nSOMERSET:\\nAy, but thou bear'd-wants that for any robbed men\\nTransmen'd at all that singless crown in't.\\n\\nANGELO:\\nNay, callet sin.\\n\\nCATESBY:\\nMy life, disbush call thee of that kern claymed as they leat'st it writ\\nTo see thee on his sweet; having eyes thee,\\nThat we have seventured in themselves both.\\n3 KING HENRY BI CAPULET:\\nWill you them grating? whose deeds dead?\\n\\nISABELLA:\\nO slee is supper!\\n\\nLADY ANNE:\\nI am the people.\\n\\nANTONIO:\\nNo bart; by Senise-day sweet,\\nNor near to comfort in thee and noth must see.\\nWe do call him and.\\n\\nGHEM:\\nNoble royal you, 'tis the pennon of a\\n. enit, there your affairs what he wholesome, for they\\nDid sisher hand, and usurping il\\nBehoned that hand som\"\n",
            " b\"ROMEO:\\nThen must I put one. But, may I resceed?\\nMy infair,\\nWhere hearings the moon of allow, to pay as mine\\nOr widely and grief! You remain made thy nemble to\\nhave my taily darks unto them hence.\\n\\nHENRY BOLINGBROKE:\\nInsolany thou, thou slept, strike!\\nIs tyo never of your silling of my sword,\\nYour music, fellow swain! I hearing, fain shiff in Frith,\\nI then were hence to heart thee in their wnole, and lay it.\\n\\nISABELLA:\\nI'll see his sin with herself,\\nAnd bringer oath that ance I'll fear.\\n\\nJULIET:\\n'sband, in gown by theseing?\\n\\nThird Citizen:\\nBecause the corse have made it conceal esteem.\\n\\nClown:\\nHousand outness of you there?\\n\\nKING RICHARD III:\\nMy natures simple, else wounded sweet, and altooy of office,\\nI pritheel fend a seel of cale is upon them dead.\\n\\nJOHN OF GLOUCE:\\nThou woundst know the sun before I let thee.\\n\\nROMEO:\\nWhen the yump this, my gracious lord;\\nMusic wars! what then?\\n\\nGidot:\\nHe cannot tell your hands.\\n\\nDUKE OF YORK:\\nIn that worthilit to to Marcius,\\nThen, and the patricians, soverg\"\n",
            " b\"ROMEO:\\nHe was sir?\\n\\nJOHN OF GAUNT:\\nNot ay, and lickle in the book.\\n\\nKATHARINA:\\nAnd being o'er this woman;\\nMine, or else I see\\nthee, steel by my head; no doubt thinks to them,\\nFor it's any king enough; who, to my sister\\nshowing the covy tried, had not postiveny's;\\nFor then I were the trith in their house,\\nOut of my faricy by the city good,\\nWe'll oft out as such assisting twat Duce.\\n\\nROMEO:\\nI will not we'll be so much learn'd frighte and jest.\\n\\nJULIET:\\nAt Siciold now, Kate, here comes to him?\\n\\nFirst As thou wast to ventage.\\n\\nCLARENCE:\\nLo,l you me dis spent before thy grievous as fire\\nMen achion without the Tower of cabused\\nAnd glean'd where you accart'd freathes fair:\\nOur king my father York, thou shalt be possess; for let him be\\nreblean, in please here? What?\\n\\nCATELBY:\\nAn eagle my master.\\n\\nTYBALT:\\nPray, dead; and let my change canqotizence\\nFrom my tent-to such a stave-no less\\nin his such as fear, I have spentation of do!\\n\\nROMEO:\\nHe thank you, for once fair cares, having not peace\\nTo victer wi\"\n",
            " b\"ROMEO:\\nThe people be it so, and now is being to thine.\\n\\nQUEEN MARGARET:\\nNorthumberlay, that's to your trifles.\\n\\nSICINIUS:\\nAt whom I must cell\\nme to the right ventures, bounding youtht!\\nBut when prove with her clear death will say I,\\nSlands for laughes a strange renown within! which will I law. Your life\\nIs Poovi's now.\\n\\nCLAUDIO:\\nSweet beloved, not one bears; for they have shown souls\\nquench them thing to this; inquire within most\\nBy night to enduch to turning\\na two you that fear as honey fault was a lady's life,\\nIn silfy rapless thousand cried as death.\\n\\nISABELLA:\\nFaith, Kate, I saw 't: in that news?\\n\\nBIANCA:\\nI'll have seen thee, then? boy, till she hath,\\nFledge seems as heapt are all order, Lurterer?\\nWhy unjust from a place: but please my face, by your hand,\\nTherefore but life to part it look, and now as leave,\\nCan life the times boring to have\\nA Coriolanus Master Frayer:' 'Setoicide dry starge;\\nThing force of Calisbery, noble to thee\\nForwath, trumpe and early day and wife,\\nAnd brief, that \"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.4061694145202637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ekspor Model Generator"
      ],
      "metadata": {
        "id": "iWXXp-fijJ2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSejBantir5r",
        "outputId": "7ffa79e2-0544-401b-c13c-1bbf5b78e8e8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7cb414b66560>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sta3e49jjIzD",
        "outputId": "b907f29a-cfc8-4613-d243-a50cf6ef1dca"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Faries the hatgest of your company:\n",
            "Intended in that Warwick's daughtes to thee?\n",
            "\n",
            "ISABELLA:\n",
            "Wome fr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tugas\n"
      ],
      "metadata": {
        "id": "li2iKaaMuAMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "    inputs, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self(inputs, training=True)\n",
        "      loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ],
      "metadata": {
        "id": "2_zqas6vuBno"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "bXI36mLUxg5q"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ],
      "metadata": {
        "id": "GpIUQSAJxobZ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uITJPqVxt9c",
        "outputId": "6aeb820b-c75e-4b90-e9da-74f47d8f35a5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172/172 [==============================] - 16s 61ms/step - loss: 2.6809\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cb3dec1b010>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  mean.reset_states()\n",
        "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "    logs = model.train_step([inp, target])\n",
        "    mean.update_state(logs['loss'])\n",
        "\n",
        "    if batch_n % 50 == 0:\n",
        "      template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "      print(template)\n",
        "\n",
        "  # saving (checkpoint) the model every 5 epochs\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "  print()\n",
        "  print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "  print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "  print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmxabmMmxwF6",
        "outputId": "a22ef0c2-d483-429b-b07c-e3dfbd6362fc"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1583\n",
            "Epoch 1 Batch 50 Loss 2.0259\n",
            "Epoch 1 Batch 100 Loss 1.9233\n",
            "Epoch 1 Batch 150 Loss 1.8117\n",
            "\n",
            "Epoch 1 Loss: 1.9587\n",
            "Time taken for 1 epoch 14.13 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.7800\n",
            "Epoch 2 Batch 50 Loss 1.7227\n",
            "Epoch 2 Batch 100 Loss 1.6437\n",
            "Epoch 2 Batch 150 Loss 1.6114\n",
            "\n",
            "Epoch 2 Loss: 1.6830\n",
            "Time taken for 1 epoch 11.40 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.5992\n",
            "Epoch 3 Batch 50 Loss 1.5567\n",
            "Epoch 3 Batch 100 Loss 1.4754\n",
            "Epoch 3 Batch 150 Loss 1.4928\n",
            "\n",
            "Epoch 3 Loss: 1.5299\n",
            "Time taken for 1 epoch 12.26 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4547\n",
            "Epoch 4 Batch 50 Loss 1.4767\n",
            "Epoch 4 Batch 100 Loss 1.4141\n",
            "Epoch 4 Batch 150 Loss 1.4511\n",
            "\n",
            "Epoch 4 Loss: 1.4351\n",
            "Time taken for 1 epoch 11.04 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.3677\n",
            "Epoch 5 Batch 50 Loss 1.3933\n",
            "Epoch 5 Batch 100 Loss 1.3971\n",
            "Epoch 5 Batch 150 Loss 1.3684\n",
            "\n",
            "Epoch 5 Loss: 1.3688\n",
            "Time taken for 1 epoch 11.02 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3154\n",
            "Epoch 6 Batch 50 Loss 1.3033\n",
            "Epoch 6 Batch 100 Loss 1.2863\n",
            "Epoch 6 Batch 150 Loss 1.3306\n",
            "\n",
            "Epoch 6 Loss: 1.3174\n",
            "Time taken for 1 epoch 10.86 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2861\n",
            "Epoch 7 Batch 50 Loss 1.2368\n",
            "Epoch 7 Batch 100 Loss 1.2850\n",
            "Epoch 7 Batch 150 Loss 1.3172\n",
            "\n",
            "Epoch 7 Loss: 1.2722\n",
            "Time taken for 1 epoch 10.89 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.1894\n",
            "Epoch 8 Batch 50 Loss 1.2379\n",
            "Epoch 8 Batch 100 Loss 1.2255\n",
            "Epoch 8 Batch 150 Loss 1.2272\n",
            "\n",
            "Epoch 8 Loss: 1.2296\n",
            "Time taken for 1 epoch 20.47 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.2047\n",
            "Epoch 9 Batch 50 Loss 1.1869\n",
            "Epoch 9 Batch 100 Loss 1.1797\n",
            "Epoch 9 Batch 150 Loss 1.2103\n",
            "\n",
            "Epoch 9 Loss: 1.1893\n",
            "Time taken for 1 epoch 10.99 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1487\n",
            "Epoch 10 Batch 50 Loss 1.1460\n",
            "Epoch 10 Batch 100 Loss 1.1819\n",
            "Epoch 10 Batch 150 Loss 1.1848\n",
            "\n",
            "Epoch 10 Loss: 1.1483\n",
            "Time taken for 1 epoch 11.36 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOAL\n",
        "Jalankan kode diatas dan sebutkan perbedaanya dengan praktikum 2?"
      ],
      "metadata": {
        "id": "kOh8BW8M3jy1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JAWAB\n",
        "Perbedaan antara kode tugas dengan praktikum 2 terletak pada prosedur pelatihan. Pada praktikum 2 menggunakan pendekatan pelatihan yang lebih sederhana dan umum digunakan, dengan **'model.fit'**. Sedangkan kode pada tugas menggambarkan pendekatan pelatihan yang lebih spesifik dan kompleks, yang dilakukan beberapa kustomisasi. Dalam pendekatan ini, mendefinisikan metode train_step dalam model turunan yang mengatur pelatihan pada tingkat batch. Secara eksplisit dilakukan perhitungan loss, gradien, dan menerapkan pembaruan bobot model dengan apply_gradients, serta menggunakan objek tf.metrics.Mean untuk menghitung rata-rata loss selama pelatihan. Pendekatan ini memberikan lebih banyak kontrol dan fleksibilitas dalam pengaturan pelatihan model.\n",
        "\n"
      ],
      "metadata": {
        "id": "AVoaaDIw3pAB"
      }
    }
  ]
}